// File generated by hilapp at Thu Mar 10 09:10:05 2022
// Git version: e3ba0735
// cmd: ../../HILA/hila/hilapp/bin/hilapp -I/opt/shared/openmpi/1.8.2/include 
//        -I/cluster/tufts/hpc/tools/spack/linux-rhel7-sandybridge/gcc-8.4.0/gcc-9.3.0-hv7dnzblbdfkadid4q76jcdpq5sfyfkb/include/c++/9.3.0 
//        -I/cluster/tufts/hpc/tools/spack/linux-rhel7-sandybridge/gcc-8.4.0/gcc-9.3.0-hv7dnzblbdfkadid4q76jcdpq5sfyfkb/lib/gcc/x86_64-pc-linux-gnu/9.3.0/../../../../include/c++/9.3.0/x86_64-pc-linux-gnu 
//        -I/cluster/tufts/hpc/tools/spack/linux-rhel7-sandybridge/gcc-8.4.0/gcc-9.3.0-hv7dnzblbdfkadid4q76jcdpq5sfyfkb/lib/gcc/x86_64-pc-linux-gnu/9.3.0/../../../../include/c++/9.3.0/backward 
//        -I/cluster/tufts/hpc/tools/spack/linux-rhel7-sandybridge/gcc-8.4.0/gcc-9.3.0-hv7dnzblbdfkadid4q76jcdpq5sfyfkb/lib/gcc/x86_64-pc-linux-gnu/9.3.0/include 
//        -I/usr/local/include -I/cluster/tufts/hpc/tools/spack/linux-rhel7-sandybridge/gcc-8.4.0/gcc-9.3.0-hv7dnzblbdfkadid4q76jcdpq5sfyfkb/include 
//        -I/cluster/tufts/hpc/tools/spack/linux-rhel7-sandybridge/gcc-8.4.0/gcc-9.3.0-hv7dnzblbdfkadid4q76jcdpq5sfyfkb/lib/gcc/x86_64-pc-linux-gnu/9.3.0/include-fixed 
//        -I/usr/include -I/opt/shared/openmpi/1.8.2/include -I/opt/shared/fftw/3.3.2/include/ 
//        -DUSE_MPI -I../../HILA/hila/hilapp/clang_include -DNDIM=3 
//        -DUSE_MPI -I/opt/shared/fftw/3.3.2/include/ -I../../HILA/hila/libraries 
//        -I../../HILA/hila/libraries/plumbing -DGIT_SHA_VALUE=b1aa3587 
//        ../../HILA/hila/libraries/plumbing/map_node_layout.cpp -o 
//        build/map_node_layout.cpt 

/// This routine uses internal MPI (or other) commands to remap the
/// node numbers so that the communications should be optimised.
///
/// Implements two calls,
/// int remap(int i) : given "computed" node index i, returns true mpi rank
///     the input i is the logical node index, runs fastest to directions x,y,z,(t)
///     must be compatible with node_rank layout!
///
/// int inverse_remap(int i) : inverse of above
///
/// Used especially in transformation coordinate -> node_rank, in
/// lattice_struct::node_rank in


// start include "plumbing/defs.h"---------------------------------
#ifndef DEFS_H_
#define DEFS_H_

// This gives us math constants, e.g. M_PI etc.
#define _USE_MATH_DEFINES

// Useful global definitions here -- this file should be included by (almost) all others

#include <iostream>
#include <array>
#include <vector>
#include <assert.h>
#include <sstream>
// #include <math.h>
#include <type_traits>
#include <cmath>


#ifdef USE_MPI
#ifdef HILAPP
// Removed by hilapp"/cluster/home/alopez07/HILA/hila/libraries/plumbing/hilapp_mpi.h"
#else
#include <mpi.h>
#endif
#endif

// Read in Makefile tunable parameters first
#include "/cluster/home/alopez07/HILA/hila/libraries/plumbing/params.h"

#ifdef HILAPP
// Removed by hilapp
#endif

#include "/cluster/home/alopez07/HILA/hila/libraries/plumbing/mersenne.h"
#include "/cluster/home/alopez07/HILA/hila/libraries/plumbing/memalloc.h" // memory allocator
#include "/cluster/home/alopez07/HILA/hila/libraries/plumbing/timing.h"


/// Define __restrict__?  It is non-standard but supported by most (all?) compilers.
/// ADD HERE GUARD FOR THOSE WHICH DO not HAVE IT
#define RESTRICT __restrict__
// #ifndef CUDA
// #define RESTRICT __restrict__
// #else
// #define RESTRICT // disabled here
// #endif


// This below declares "out_only" -qualifier.  It is empty on purpose. Do not remove!
#define out_only
// out_only for methods tells hilapp that the base variable original value is not
// needed: class C {
//    int set() out_only { .. }
// };
// indicates that a.set(); does not need original value of a.
// Can also be used in function arguments:
//    int func( out_only double & p, ..);

// Defined empty on purpose, same as above!
#define const_function
// const_function does not change the base variable, but can return a (non-const)
// reference. Needed typically for access operators for loop extern variables:
//     class v {
//         double c[N];
//         double & e(const int i) const_function { return c[i]; }
//     };
//
//     v vv;
//     Field<v>  f;
//     onsites(ALL) { f[X].e(0) += vv.e(0); }
// This would not work without const_function, because vv.e(1) might modify loop
// extern variable vv, which is not allowed.  If method is marked "const",
// then the assignment would not work.
//
// const_function is weaker than const.


// text output section -- defines also output0, which writes from node 0 only
namespace hila {

/// this is our default output file stream
extern std::ostream output;
/// this is just a hook to store output file, if it is in use
extern std::ofstream output_file;

// about_to_finish becomes true at the end.  Signals that
// better not rely on MPI or existence of objects any more.
extern bool about_to_finish;

// check_input is used to notify that we're just checking the
// input values and will exit before fields are allocated.
extern bool check_input;
extern int check_with_nodes;

// optional input filename
extern const char *input_file;

void initialize(int argc, char **argv);
void finishrun();
void terminate(int status);
void error(const std::string &msg);
void error(const char *msg);


/// rank of this node
int myrank();
/// how many nodes there are
int number_of_nodes();
/// synchronize mpi
void synchronize();


} // namespace hila

// The logger uses hila::myrank, so it cannot be included on top
#include "/cluster/home/alopez07/HILA/hila/libraries/plumbing/logger.h"
namespace hila {
/// Now declare the logger
extern logger_class log;
} // namespace hila

/// We want to define ostream
///     "output0 << stuff;"
/// which is done only by rank 0.
/// This is hacky but easy.  Probably should be done without #define.
/// Do this through else-branch in order to avoid if-statement problems.
/// #define output0 if (hila::myrank() != 0) {} else hila::output
///
/// Above #define can trigger "dangling-else" warning.  Let us
/// try to avoid it with the following a bit more ugly trick:
#define output0                                                                        \
    for (int _dummy_i_ = 1; hila::myrank() == 0 && _dummy_i_; --_dummy_i_)             \
    hila::output

// The following disables the "dangling-else" warning, but not needed now
//#if defined(__clang__) || defined(__GNUC__)
//#pragma GCC diagnostic ignored "-Wdangling-else"
//#endif

/// define a class for FFT direction
enum class fft_direction { forward, back };

// trivial template for helping vectorization
template <typename T>
using element = T;

// Backend defs-headers

#if defined(CUDA) || defined(HIP)
#include "plumbing/backend_cuda/defs.h"
#elif defined(AVX)
#include "plumbing/backend_vector/defs.h"
#else
#include "/cluster/home/alopez07/HILA/hila/libraries/plumbing/backend_cpu/defs.h"
#endif

// this include has to be after the backend defs, because those define hila::random()
#include "/cluster/home/alopez07/HILA/hila/libraries/plumbing/random.h"

// This contains useful template tools
#include "/cluster/home/alopez07/HILA/hila/libraries/plumbing/type_tools.h"

#if defined(CUDA) || defined(HIP)
#include "plumbing/backend_cuda/cuda_templated_ops.h"
#endif

// Include some basic functions for real (non-class) vars,
// to help with generic code
#include "/cluster/home/alopez07/HILA/hila/libraries/plumbing/real_var_ops.h"

// MPI Related functions and definitions
#define MAX_GATHERS 1000

#ifndef USE_MPI

// broadcast does nothing if not MPI
template <typename T>
void broadcast(T &v) {}

template <typename T>
void broadcast_array(T *var, int n) {}

#endif

void initialize_communications(int &argc, char ***argv);
void split_into_sublattices(int rank);
bool is_comm_initialized(void);
void finish_communications();
void abort_communications(int status);

// and print a dashed line
void print_dashed_line(const std::string &txt = {});


#endif
// end include "plumbing/defs.h"---------------------------------

#include "/cluster/home/alopez07/HILA/hila/libraries/plumbing/lattice.h"

#if defined(NODE_LAYOUT_TRIVIAL)

////////////////////////////////////////////////////////////////////
// This is the trivial version, so that the order is unmodified
////////////////////////////////////////////////////////////////////

void lattice_struct::allnodes::create_remap() {
    output0 << "Node remapping: NODE_LAYOUT_TRIVIAL (no reordering)\n";
    lattice->nodes.map_array = nullptr;
    lattice->nodes.map_inverse = nullptr;
}

unsigned lattice_struct::allnodes::remap(unsigned i) {
    return i;
}

unsigned lattice_struct::allnodes::inverse_remap(unsigned i) {
    return i;
}


#elif defined(NODE_LAYOUT_BLOCK)

////////////////////////////////////////////////////////////////////
// Arrange nodes so that NODE_LAYOUT_BLOCK nodes are "close"
//
// For example, in 2d and NODE_LAYOUT_BLOCK = 4 the MPI indices run as
//
//  1  2 |  5  6 | 9  10
//  3  4 |  7  8 | 11 12
//  -----+-------+------
// 13 14 | 17 18 | 21 22
// 15 16 | 19 20 | 23 24
//
////////////////////////////////////////////////////////////////////

void lattice_struct::allnodes::create_remap() {

    output0 << "Node remapping: NODE_LAYOUT_BLOCK with blocksize " << NODE_LAYOUT_BLOCK
            << '\n';

    // let us allow only factors of 5,3 and 2 in NODE_LAYOUT_BLOCK
    CoordinateVector blocksize;
    CoordinateVector blockdivs = lattice->nodes.n_divisions;
    int nblocks = NODE_LAYOUT_BLOCK;
    blocksize.fill(1);

    bool found = true;
    while (found && nblocks > 1) {

        found = false; // if not divisible stop trying
        foralldir (d) {
            // divide directions one by one
            int div;
            for (div = 2; div <= 5; div++)
                if (nblocks % div == 0 && blockdivs[d] % div == 0)
                    break;
            if (div <= 5) {
                blocksize[d] *= div;
                blockdivs[d] /= div;
                nblocks /= div;
                found = true;
            }
        }
    }

    output0 << "Node block size " << blocksize << "  block division " << blockdivs << '\n';

    // now blocksize tells us how many nodes to each direction in block
    // these are taken in order

    lattice->nodes.map_array =
        (unsigned *)memalloc(lattice->nodes.number * sizeof(unsigned));
    // we don't need the inverse at the moment?
    // lattice->nodes.map_inverse = (unsigned *)memalloc(lattice->nodes.number *
    // sizeof(unsigned));
    lattice->nodes.map_inverse = nullptr;

    nblocks = 1;
    foralldir (d)
        nblocks *= blocksize[d];

    // Loop over the "logical" node indices (i.e.)

    for (int i = 0; i < lattice->nodes.number; i++) {
        // lcoord is the coordinate of the logical node,
        // bcoord the block coord and icoord coord inside block
        CoordinateVector lcoord, bcoord, icoord;
        int idiv = i;
        foralldir (d) {
            lcoord[d] = idiv % lattice->nodes.n_divisions[d];
            idiv /= lattice->nodes.n_divisions[d];

            bcoord[d] = lcoord[d] / blocksize[d];
            icoord[d] = lcoord[d] % blocksize[d];
        }

        // ii - index within a block
        // bi - index of a block
        int ii, bi, im, bm;
        ii = bi = 0;
        im = bm = 1;
        foralldir(d) {
            ii += icoord[d] * im;
            im *= blocksize[d];

            bi += bcoord[d] * bm;
            bm *= blockdivs[d];
        }

        // output0 << lcoord << bcoord << icoord << '\n';
        // output0 << "ii " << ii << " bi " << bi << '\n';

        lattice->nodes.map_array[i] = bi * nblocks + ii;
    }
}

/// And the call interface for remapping

unsigned lattice_struct::allnodes::remap(unsigned i) {
    return lattice->nodes.map_array[i];
}

unsigned lattice_struct::allnodes::inverse_remap(unsigned idx) {
    for (int i = 0; i < lattice->nodes.number; i++)
        if (lattice->nodes.map_array[i] == idx)
            return i;

    return 1 << 30; // big number, crash
}


#else

NODE_LAYOUT_BLOCK or NODE_LAYOUT_TRIVIAL must be defined

#endif
